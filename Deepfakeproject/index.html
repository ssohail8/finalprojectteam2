<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Synthesis & Deepfake Technology</title>
    <link rel="stylesheet" href="styles.css">
    <script defer src="script.js"></script>
</head>
<body>
    <header>
        <div class="container">
            <h1>Voice Synthesis & Deepfake Technology</h1>
            <nav>
                <ul class="tabs">
                    <li data-tab="introduction">Introduction</li>
                    <li data-tab="applications">Applications</li>
                    <li data-tab="discussion">Critical Discussion</li>
                    <li data-tab="recommendations">Recommendations</li>
                    <li data-tab="sources">Sources</li>
                    <li data-tab="about">About Us</li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section id="introduction" class="tab-content active">
            <div class="container">
                <h2>Introduction to Technology: Voice Synthesis and Deepfake Technology</h2>
                <p><strong>Chosen Technology:</strong> The team chose Voice Synthesis and Deepfake Technology for our final project. This technology uses complex artificial intelligence to create sounds and voices that mimic human speech very closely.</p>
                <p><strong>Description:</strong> Voice Synthesis and Deepfake Technology are advanced tools in artificial intelligence that allow machines to produce sounds that are very similar to human speech. Voice synthesis takes written text and turns it into spoken words, which is useful for things like virtual assistants and language translation apps. Deepfake technology builds on this by using more advanced techniques to copy a person’s way of speaking so closely that it can sound just like them. This technology is used in various ways, from making entertainment more engaging to being used in harmful ways like spreading false information. While these tools offer great benefits, like helping people with disabilities, they also come with serious challenges, such as issues of privacy and the potential to spread misleading information.</p>
                <p><strong>Reason for Choice:</strong> We chose this technology because it has great potential to help as well as harm. On the positive side, it can change industries and improve lives, like making speaking devices better for people who can't see or speak. It also allows creators to bring back the voices of famous people who have passed away for movies and shows. On the negative side, it can be used to make fake news or misleading content that can trick people, which is harmful to society. By studying this technology, we want to fully understand how it works and push for rules and tools that ensure it is used responsibly.</p>
                <div class="image-container">
                    <a href="https://www.forbes.com/councils/forbestechcouncil/2021/05/10/analyzing-the-rise-of-deepfake-voice-technology/" target="_blank">
                        <img src="forbes.png" alt="Analyzing the Rise of Deepfake Voice Technology" />
                    </a>
                    <p>Click the image to read the Forbes article, "Analyzing the Rise of Deepfake Voice Technology."</p>
                </div>
                <div class="image-container">
                    <a href="https://vivoka.com/how-to-speech-synthesis-tts/" target="_blank">
                        <img src="vivoka.png" alt="How to Speech Synthesis TTS - Vivoka" />
                    </a>
                    <p>Click the image to learn more about speech synthesis and TTS technology on Vivoka.</p>
                </div>
                <div class="image-container">
                    <a href="https://www.safespace.qa/en/topic/deepfake-technology-definition-and-how-recognize-it" target="_blank">
                        <img src="deepfake.png" alt="Deepfake Technology - SafeSpace" />
                    </a>
                    <p>Click the image to read about deepfake technology and how to recognize it on SafeSpace.</p>
                </div>
            </div>
        </section>

        <section id="applications" class="tab-content">
            <div class="container">
                <h2>Applications of the Technology</h2>
                <h3>Real-World Examples:</h3>
                <ul>
                    <li><strong>Entertainment Industry:</strong> Deepfakes and AI voices are becoming more common in entertainment. A well-known example is the TV show "The Mandalorian," where this technology was used to make an actor look and sound younger, showing how AI can keep actors in roles longer, even after they age or pass away.</li>
                    <li><strong>Misinformation and Fraud:</strong> This technology has also been used in politics. For example, during the 2024 US Presidential Elections, deepfakes were made to manipulate public views about candidates, showing how it can be used to mislead people.</li>
                </ul>
                <h3>Complexity and Challenges:</h3>
                <p>Using AI to create deepfakes and synthetic voices brings up many ethical issues. Misleading videos that make it look like public figures are saying things they didn't have become common ways to spread false information. Currently, there are few rules on who can be shown in these videos, making it easy for anyone to misuse this technology. This lack of control leads to privacy issues and increases fraud, as bad actors can easily trick people by imitating someone else's voice. Managing these risks while keeping the benefits is a big challenge.</p>
                <div class="image-container">
                    <a href="https://www.dhs.gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0.pdf" target="_blank">
                        <img src="dhs.png" alt="Increasing Threats of Deepfake Identities - DHS" />
                    </a>
                    <p>Click the image to read about increasing threats of deepfake identities in the DHS report.</p>
                </div>
                <div class="image-container">
                    <a href="https://www.statista.com/chart/31901/countries-per-region-with-biggest-increases-in-deepfake-specific-fraud-cases/" target="_blank">
                        <img src="statista.png" alt="Deepfake-Specific Fraud Cases - Statista" />
                    </a>
                    <p>Click the image to explore data on deepfake-specific fraud cases by country on Statista.</p>
                </div>
            </div>
        </section>

        <section id="discussion" class="tab-content">
            <div class="container">
                <h2>Critical Discussion of the Technology and Its Applications</h2>
                <h3>Social and Political Implications:</h3>
                <p>The ability to make realistic but false content could damage the fairness of elections by making up fake endorsements or speeches. This can mislead people and change the outcome of elections. Also, using someone's image without permission can lead to problems like harassment and harm a person’s reputation. Moreover, spreading false information can weaken trust in media and disrupt how society communicates.</p>
                <div class="image-container">
                    <a href="https://www.npr.org/2024/02/08/1229641751/ai-deepfakes-election-risks-lawmakers-tech-companies-artificial-intelligence" target="_blank">
                        <img src="npr.png" alt="AI Deepfakes Election Risks - NPR" />
                    </a>
                    <p>Click the image to read about how AI deepfakes pose election risks, as discussed by lawmakers and tech companies on NPR.</p>
                </div>
                <h3>Ethical Perspectives:</h3>
                <ul>
                    <li><strong>Utilitarian Perspective:</strong> This view looks at whether the good effects of the technology for many people outweigh the bad. If the benefits, such as helping disabled individuals or educational uses, are greater than the negatives like false information or invading privacy, then the technology might be seen as acceptable.</li>
                    <li><strong>Deontological Perspective:</strong> This approach focuses on whether the actions themselves are right or wrong, rather than the results. Here, making and using deepfakes would be wrong if it involves lying or pretending to be someone else, no matter what benefits might come from it.</li>
                    <li><strong>Virtue Ethics:</strong> This perspective considers the character and intentions of the people using the technology. Good uses would be those that show qualities like honesty and kindness, while bad uses would be those that deceive or hurt others.</li>
                </ul>
                <div class="image-container">
                    <a href="https://www.orfonline.org/expert-speak/debating-the-ethics-of-deepfakes" target="_blank">
                        <img src="orf.png" alt="Debating the Ethics of Deepfakes - ORF" />
                    </a>
                    <p>Click the image to explore ethical debates surrounding deepfake technology on ORF.</p>
                </div>
                <div class="image-container">
                    <a href="https://medium.com/@navarai/the-ethical-dilemmas-of-deepfake-technology-navigating-reality-in-the-digital-world-67479aa15615" target="_blank">
                        <img src="medium.png" alt="The Ethical Dilemmas of Deepfake Technology - Medium" />
                    </a>
                    <p>Click the image to read about the ethical dilemmas of deepfake technology on Medium.</p>
                </div>
            </div>
        </section>

        <section id="recommendations" class="tab-content">
            <div class="container">
                <h2>Future Recommendations</h2>
                <ul>
                    <li><strong>Technological Strategies:</strong> Develop better technologies that can detect fake content more accurately. These tools could be used on platforms where videos and audio are shared to help spot fakes automatically.</li>
                    <li><strong>Social Strategies:</strong> Teach the public about what deepfake technology can do and the risks it carries. Programs that improve people’s ability to recognize fake media can help them be more cautious.</li>
                    <li><strong>Policy-Level Recommendations:</strong> Governments need to create clear rules that outline what is allowed with deepfake technology and punish misuse strongly. Laws should protect people’s rights to their own images and require clear permission for using someone’s likeness.</li>
                </ul>
                <div class="image-container">
                    <a href="https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/" target="_blank">
                        <img src="weforum.png" alt="Future-Proofing Against Deepfakes - WEForum" />
                    </a>
                    <p>Click the image to explore 4 ways to future-proof against deepfakes on WEForum.</p>
                </div>
                <div class="image-container">
                    <a href="https://etedge-insights.com/technology/artificial-intelligence/deepfakes-and-the-future-of-digital-security-are-we-ready/" target="_blank">
                        <img src="insights.png" alt="Deepfakes and the Future of Digital Security - Insights" />
                    </a>
                    <p>Click the image to learn about deepfakes and the future of digital security on Insights.</p>
                </div>
            </div>
        </section>

        <section id="sources" class="tab-content">
            <div class="container">
                <h2>Sources</h2>
                <h3>Real-World Examples</h3>
                <ul>
                    <li>Respeecher. (n.d.). <em>Respeecher synthesized younger Luke Skywalker’s voice for Disney’s The Mandalorian</em>. Retrieved from <a href="https://www.respeecher.com/case-studies/respeecher-synthesized-younger-luke-skywalkers-voice-disneys-mandalorian" target="_blank">https://www.respeecher.com/case-studies/respeecher-synthesized-younger-luke-skywalkers-voice-disneys-mandalorian</a></li>
                    <li>The New York Times. (2023, February 7). <em>Artificial intelligence training deepfake</em>. Retrieved from <a href="https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html" target="_blank">https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html</a></li>
                    <li>YouTube. (n.d.). <em>The power of deepfake technology in real-world scenarios</em>. Retrieved from <a href="https://youtu.be/t52Bi-ZUZjA?si=vDu1WKNdgEJKp931" target="_blank">https://youtu.be/t52Bi-ZUZjA?si=vDu1WKNdgEJKp931</a></li>
                </ul>
                <h3>Introduction to Technology</h3>
                <ul>
                    <li>Forbes Technology Council. (2021, May 10). <em>Analyzing the rise of deepfake voice technology</em>. Retrieved from <a href="https://www.forbes.com/councils/forbestechcouncil/2021/05/10/analyzing-the-rise-of-deepfake-voice-technology/" target="_blank">https://www.forbes.com/councils/forbestechcouncil/2021/05/10/analyzing-the-rise-of-deepfake-voice-technology/</a></li>
                    <li>Vivoka. (n.d.). <em>How to speech synthesis TTS</em>. Retrieved from <a href="https://vivoka.com/how-to-speech-synthesis-tts/" target="_blank">https://vivoka.com/how-to-speech-synthesis-tts/</a></li>
                    <li>SafeSpace. (n.d.). <em>Deepfake technology: Definition and how to recognize it</em>. Retrieved from <a href="https://www.safespace.qa/en/topic/deepfake-technology-definition-and-how-recognize-it" target="_blank">https://www.safespace.qa/en/topic/deepfake-technology-definition-and-how-recognize-it</a></li>
                </ul>
                <h3>Social and Political Implications</h3>
                <ul>
                    <li>NPR. (2024, February 8). <em>AI deepfakes pose election risks: What lawmakers and tech companies are doing</em>. Retrieved from <a href="https://www.npr.org/2024/02/08/1229641751/ai-deepfakes-election-risks-lawmakers-tech-companies-artificial-intelligence" target="_blank">https://www.npr.org/2024/02/08/1229641751/ai-deepfakes-election-risks-lawmakers-tech-companies-artificial-intelligence</a></li>
                </ul>
                <h3>Ethical Perspectives</h3>
                <ul>
                    <li>Observer Research Foundation. (n.d.). <em>Debating the ethics of deepfakes</em>. Retrieved from <a href="https://www.orfonline.org/expert-speak/debating-the-ethics-of-deepfakes" target="_blank">https://www.orfonline.org/expert-speak/debating-the-ethics-of-deepfakes</a></li>
                    <li>Navarai. (n.d.). <em>The ethical dilemmas of deepfake technology: Navigating reality in the digital world</em>. Medium. Retrieved from <a href="https://medium.com/@navarai/the-ethical-dilemmas-of-deepfake-technology-navigating-reality-in-the-digital-world-67479aa15615" target="_blank">https://medium.com/@navarai/the-ethical-dilemmas-of-deepfake-technology-navigating-reality-in-the-digital-world-67479aa15615</a></li>
                </ul>
                <h3>Complexity and Challenges</h3>
                <ul>
                    <li>Department of Homeland Security. (n.d.). <em>Increasing threats of deepfake identities</em>. Retrieved from <a href="https://www.dhs.gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0.pdf" target="_blank">https://www.dhs.gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0.pdf</a></li>
                    <li>Statista. (n.d.). <em>Countries with biggest increases in deepfake-specific fraud cases</em>. Retrieved from <a href="https://www.statista.com/chart/31901/countries-per-region-with-biggest-increases-in-deepfake-specific-fraud-cases/" target="_blank">https://www.statista.com/chart/31901/countries-per-region-with-biggest-increases-in-deepfake-specific-fraud-cases/</a></li>
                </ul>
                <h3>Future Recommendations</h3>
                <ul>
                    <li>World Economic Forum. (2024, February). <em>4 ways to future-proof against deepfakes in 2024 and beyond</em>. Retrieved from <a href="https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/" target="_blank">https://www.weforum.org/stories/2024/02/4-ways-to-future-proof-against-deepfakes-in-2024-and-beyond/</a></li>
                    <li>ET Edge Insights. (n.d.). <em>Deepfakes and the future of digital security: Are we ready?</em>. Retrieved from <a href="https://etedge-insights.com/technology/artificial-intelligence/deepfakes-and-the-future-of-digital-security-are-we-ready/" target="_blank">https://etedge-insights.com/technology/artificial-intelligence/deepfakes-and-the-future-of-digital-security-are-we-ready/</a></li>
                </ul>
            </div>
        </section>

        <section id="about" class="tab-content">
            <div class="container">
                <h2>About Us</h2>
                <p>Group Members: Sabeeh Sohail, Brendin Kim, Nusrat Jahan, Sandy Tran</p>
                <p>Class: IT-304-DL4</p>
                <p>This project explores the ethical and practical implications of Voice Synthesis and Deepfake Technology.</p>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>© 2024 Team 2 - IT 304</p>
        </div>
    </footer>
</body>
</html>